{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "- [Blog](https://medium.com/@awjuliani/simple-reinforcement-learning-with-tensorflow-part-3-model-based-rl-9a6fe0cce99)\n",
    "  - [Github](https://github.com/awjuliani/DeepRL-Agents/blob/master/Model-Network.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# helpers\n",
    "def resetBuffer(buffer):\n",
    "    for arr in buffer:\n",
    "        arr[:] = 0\n",
    "\n",
    "def discountRewards(rewards, discount_rate=0.99):\n",
    "    \"\"\"\n",
    "    rewards: 1D numpy array of rewards\n",
    "    \"\"\"\n",
    "    discounted_rewards = np.zeros_like(rewards)\n",
    "    running_sum = 0\n",
    "    for i in reversed(range(len(rewards))):\n",
    "        running_sum = discount_rate * running_sum + rewards[i]\n",
    "        discounted_rewards[i] = running_sum\n",
    "    return discounted_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-21 13:25:27,581] Making new env: CartPole-v0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returns an initializer performing \"Xavier\" initialization for weights.\n",
      "\n",
      "  This function implements the weight initialization from:\n",
      "\n",
      "  Xavier Glorot and Yoshua Bengio (2010):\n",
      "           Understanding the difficulty of training deep feedforward neural\n",
      "           networks. International conference on artificial intelligence and\n",
      "           statistics.\n",
      "\n",
      "  This initializer is designed to keep the scale of the gradients roughly the\n",
      "  same in all layers. In uniform distribution this ends up being the range:\n",
      "  `x = sqrt(6. / (in + out)); [-x, x]` and for normal distribution a standard\n",
      "  deviation of `sqrt(3. / (in + out))` is used.\n",
      "\n",
      "  Args:\n",
      "    uniform: Whether to use uniform or normal distributed random initialization.\n",
      "    seed: A Python integer. Used to create random seeds. See\n",
      "      [`set_random_seed`](../../api_docs/python/constant_op.md#set_random_seed)\n",
      "      for behavior.\n",
      "    dtype: The data type. Only floating point types are supported.\n",
      "\n",
      "  Returns:\n",
      "    An initializer for a weight matrix.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(tf.contrib.layers.xavier_initializer.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gets an existing variable with these parameters or create a new one.\n",
      "\n",
      "This function prefixes the name with the current variable scope\n",
      "and performs reuse checks. See the\n",
      "@{$variable_scope$Variable Scope How To}\n",
      "for an extensive description of how reusing works. Here is a basic example:\n",
      "\n",
      "```python\n",
      "with tf.variable_scope(\"foo\"):\n",
      "    v = tf.get_variable(\"v\", [1])  # v.name == \"foo/v:0\"\n",
      "    w = tf.get_variable(\"w\", [1])  # w.name == \"foo/w:0\"\n",
      "with tf.variable_scope(\"foo\", reuse=True):\n",
      "    v1 = tf.get_variable(\"v\")  # The same as v above.\n",
      "```\n",
      "\n",
      "If initializer is `None` (the default), the default initializer passed in\n",
      "the variable scope will be used. If that one is `None` too, a\n",
      "`glorot_uniform_initializer` will be used. The initializer can also be\n",
      "a Tensor, in which case the variable is initialized to this value and shape.\n",
      "\n",
      "Similarly, if the regularizer is `None` (the default), the default regularizer\n",
      "passed in the variable scope will be used (if that is `None` too,\n",
      "then by default no regularization is performed).\n",
      "\n",
      "If a partitioner is provided, a `PartitionedVariable` is returned.\n",
      "Accessing this object as a `Tensor` returns the shards concatenated along\n",
      "the partition axis.\n",
      "\n",
      "Some useful partitioners are available.  See, e.g.,\n",
      "`variable_axis_size_partitioner` and `min_max_variable_partitioner`.\n",
      "\n",
      "Args:\n",
      "  name: The name of the new or existing variable.\n",
      "  shape: Shape of the new or existing variable.\n",
      "  dtype: Type of the new or existing variable (defaults to `DT_FLOAT`).\n",
      "  initializer: Initializer for the variable if one is created.\n",
      "  regularizer: A (Tensor -> Tensor or None) function; the result of\n",
      "    applying it on a newly created variable will be added to the collection\n",
      "    @{tf.GraphKeys.REGULARIZATION_LOSSES} and can be used for regularization.\n",
      "  trainable: If `True` also add the variable to the graph collection\n",
      "    `GraphKeys.TRAINABLE_VARIABLES` (see `tf.Variable`).\n",
      "collections: List of graph collections keys to add the Variable to.\n",
      "    Defaults to `[GraphKeys.GLOBAL_VARIABLES]` (see `tf.Variable`).\n",
      "  caching_device: Optional device string or function describing where the\n",
      "    Variable should be cached for reading.  Defaults to the Variable's\n",
      "    device.  If not `None`, caches on another device.  Typical use is to\n",
      "    cache on the device where the Ops using the Variable reside, to\n",
      "    deduplicate copying through `Switch` and other conditional statements.\n",
      "  partitioner: Optional callable that accepts a fully defined `TensorShape`\n",
      "    and `dtype` of the Variable to be created, and returns a list of\n",
      "    partitions for each axis (currently only one axis can be partitioned).\n",
      "  validate_shape: If False, allows the variable to be initialized with a\n",
      "      value of unknown shape. If True, the default, the shape of initial_value\n",
      "      must be known.\n",
      "  use_resource: If False, creates a regular Variable. If true, creates an\n",
      "    experimental ResourceVariable instead with well-defined semantics.\n",
      "    Defaults to False (will later change to True).\n",
      "  custom_getter: Callable that takes as a first argument the true getter, and\n",
      "    allows overwriting the internal get_variable method.\n",
      "    The signature of `custom_getter` should match that of this method,\n",
      "    but the most future-proof version will allow for changes:\n",
      "    `def custom_getter(getter, *args, **kwargs)`.  Direct access to\n",
      "    all `get_variable` parameters is also allowed:\n",
      "    `def custom_getter(getter, name, *args, **kwargs)`.  A simple identity\n",
      "    custom getter that simply creates variables with modified names is:\n",
      "    ```python\n",
      "    def custom_getter(getter, name, *args, **kwargs):\n",
      "      return getter(name + '_suffix', *args, **kwargs)\n",
      "    ```\n",
      "\n",
      "Returns:\n",
      "  The created or existing `Variable` (or `PartitionedVariable`, if a\n",
      "  partitioner was used).\n",
      "\n",
      "Raises:\n",
      "  ValueError: when creating a new variable and shape is not declared,\n",
      "    when violating reuse during variable creation, or when `initializer` dtype\n",
      "    and `dtype` don't match. Reuse is set inside `variable_scope`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tf.get_variable.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "num_hidden_neurons = 8\n",
    "learn_rate = 1e-2\n",
    "discount_rate = 0.99\n",
    "rmsp_decay_rate = 0.99\n",
    "\n",
    "model_batch_size = 3\n",
    "env_batch_size = 3\n",
    "\n",
    "env_input_size, = env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Policy NN\n",
    "tf.reset_default_graph()\n",
    "# input observation\n",
    "observations = tf.placeholder(tf.float32, shape=[None, 4], name=\"policy/input_layer\")\n",
    "# two relu layers nn\n",
    "W1 = tf.get_variable(\"policy/W1\", \n",
    "                     shape=[4, num_hidden_neurons], \n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "layer1 = tf.nn.relu(tf.matmul(observations, W1))\n",
    "W2 = tf.get_variable(\"policy/W2\", \n",
    "                     shape=[num_hidden_neurons, 1],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "# policy_predict is a 1D array which ideally should be a vector of 0 and 1 \n",
    "# (0 -> move left, 1 -> move right)\n",
    "# predict_policy shape: [None, 1] \n",
    "predict_policy = tf.nn.sigmoid(tf.matmul(layer1, W2), name=\"policy/predict_policy\")\n",
    "\n",
    "train_variables = tf.trainable_variables()\n",
    "target_policy = tf.placeholder(tf.float32, shape=[None, 1], name=\"policy/target_policy\")\n",
    "advantages = tf.placeholder(tf.float32, name=\"policy/advantages\")\n",
    "W1Grad = tf.placeholder(tf.float32, name=\"policy/batch_grad1\")\n",
    "W2Grad = tf.placeholder(tf.float32, name=\"policy/batch_grad2\")\n",
    "batch_grads = [W1Grad, W2Grad]\n",
    "# if target_policy == 1: loglik = tf.log(1 - predict_policy) --> predict_policy == 1 is optimal\n",
    "# if target_policy == 0: loglik = tf.log(predict_policy) --> predict_policy == 0 is optimal\n",
    "loglik = tf.log(target_policy*(target_policy - predict_policy) + (1-target_policy)*(target_policy + predict_policy))\n",
    "\n",
    "loss = -tf.reduce_sum(loglik*advantages)\n",
    "newGrads = tf.gradients(loss, train_variables)\n",
    "train_policy_op = tf.train.AdamOptimizer(learning_rate=learn_rate).apply_gradients(zip(batch_grads, train_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Model NN\n",
    "num_hidden_neurons_model = 256\n",
    "\n",
    "with tf.variable_scope(\"rnnlm\"):\n",
    "    # env_inpu_size+1: environment state + action\n",
    "    previous_state = tf.placeholder(tf.float32, [None, env_input_size+1])\n",
    "    W1_m = tf.get_variable(\"W1_m\", \n",
    "                           shape=[5, num_hidden_neurons_model],\n",
    "                           initializer=tf.contrib.layers.xavier_initializer())\n",
    "    B1_m = tf.Variable(tf.zeros((num_hidden_neurons_model)), name=\"B1_m\")\n",
    "    layer1_m = tf.nn.relu(tf.matmul(previous_state, W1_m) + B1_m)\n",
    "    \n",
    "    W2_m = tf.get_variable(\"W2_m\",\n",
    "                           shape=[num_hidden_neurons_model, num_hidden_neurons_model],\n",
    "                           initializer=tf.contrib.layers.xavier_initializer())\n",
    "    B2_m = tf.Variable(tf.zeros((num_hidden_neurons_model)), name=\"B2_m\")\n",
    "    layer2_m = tf.nn.relu(tf.matmul(layer1_m, W2_m) + B2_m)\n",
    "    \n",
    "    # output weight for observation\n",
    "    wO = tf.get_variable(\"wO\", \n",
    "                         shape=[num_hidden_neurons_model, 4],\n",
    "                         initializer=tf.contrib.layers.xavier_initializer())\n",
    "    bO = tf.Variable(tf.zeros((4)), name=\"bO\")\n",
    "    \n",
    "    # output weight for reward\n",
    "    wR = tf.get_variable(\"wR\",\n",
    "                         shape=[num_hidden_neurons_model, 1],\n",
    "                         initializer=tf.contrib.layers.xavier_initializer())\n",
    "    bR = tf.Variable(tf.zeros((1)), name=\"bR\")\n",
    "    \n",
    "    # output weight for done\n",
    "    wD = tf.get_variable(\"wD\",\n",
    "                         shape=[num_hidden_neurons_model, 1],\n",
    "                         initializer=tf.contrib.layers.xavier_initializer())\n",
    "    bD = tf.Variable(tf.zeros((1)), name=\"bD\")\n",
    "    \n",
    "    predict_observation = tf.matmul(layer2_m, wO) + bO\n",
    "    predict_reward = tf.matmul(layer2_m, wR) + bR\n",
    "    predict_done = tf.matmul(layer2_m, wD) + bD\n",
    "    \n",
    "    target_observation = tf.placeholder(tf.float32, [None, 4], name=\"target_observation\")\n",
    "    target_reward = tf.placeholder(tf.float32, [None, 1], name=\"target_reward\")\n",
    "    target_done = tf.placeholder(tf.float32, [None, 1], name=\"target_done\")\n",
    "    \n",
    "    loss_observation = tf.square(target_observation - predict_observation)\n",
    "    loss_reward = tf.square(target_reward - predict_reward)\n",
    "    loss_done = -tf.log(target_done*predict_done + (1-target_done)*(1-predict_done))\n",
    "    loss = tf.reduce_sum(loss_observation + loss_reward + loss_done)\n",
    "    \n",
    "    train_op_model = tf.train.AdamOptimizer(learning_rate=learn_rate).minimize(loss)\n",
    "    predict_state = tf.concat([predict_observation, predict_reward, predict_done], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# traing helper\n",
    "def stepModel(sess, xs, action):\n",
    "    toFeed = np.reshape(np.hstack([xs[-1][0], np.array(action)]), (1, 5))\n",
    "    predict_ = sess.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04686382, -0.02429138,  0.04838109,  0.04020312])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset() # position, cart-velocity, pole-angle, pole-vel-at-tip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
